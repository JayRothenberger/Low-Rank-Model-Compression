{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "def dino_model():\n",
    "    os.environ['TORCH_HOME'] = '/vagrant/pytorch_models/'\n",
    "    os.environ['TORCH_HUB'] = '/vagrant/pytorch_models/'\n",
    "    # DINOv2 vit-s (14) with registers\n",
    "    model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14_reg')\n",
    "    # state = model.state_dict()\n",
    "    # mymodel = vit_small(14, 4)\n",
    "    # mymodel.load_state_dict(state)\n",
    "    model.eval()\n",
    "\n",
    "    return model.to('cpu')\n",
    "\n",
    "def dino_transforms():\n",
    "    return v2.Compose(\n",
    "                    [\n",
    "                        torchvision.transforms.ToTensor(),\n",
    "                        transforms.Resize(size=(256, 256), antialias=True),\n",
    "                        transforms.CenterCrop((224, 224)),\n",
    "                        transforms.Normalize(\n",
    "                                            mean=[0.485, 0.456, 0.406],\n",
    "                                            std=[0.229, 0.224, 0.225]\n",
    "                                            ),\n",
    "                    ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaycr\\anaconda3\\envs\\tfnew\\lib\\site-packages\\torch\\hub.py:365: UserWarning: TORCH_HUB is deprecated, please use env TORCH_HOME instead\n",
      "  warnings.warn('TORCH_HUB is deprecated, please use env TORCH_HOME instead')\n",
      "Using cache found in /vagrant/pytorch_models/hub\\facebookresearch_dinov2_main\n",
      "c:\\vagrant/pytorch_models/hub\\facebookresearch_dinov2_main\\dinov2\\layers\\swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "c:\\vagrant/pytorch_models/hub\\facebookresearch_dinov2_main\\dinov2\\layers\\attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "c:\\vagrant/pytorch_models/hub\\facebookresearch_dinov2_main\\dinov2\\layers\\block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    }
   ],
   "source": [
    "DINOv2 = dino_model()\n",
    "DINOv2_transform = dino_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-23): 24 x NestedTensorBlock(\n",
       "    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): MemEffAttention(\n",
       "      (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls1): LayerScale()\n",
       "    (drop_path1): Identity()\n",
       "    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (act): GELU(approximate='none')\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls2): LayerScale()\n",
       "    (drop_path2): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DINOv2.blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=384, out_features=1536, bias=True)\n",
      "Linear(in_features=1536, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=1152, bias=True)\n",
      "Linear(in_features=384, out_features=1536, bias=True)\n",
      "Linear(in_features=1536, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=1152, bias=True)\n",
      "Linear(in_features=384, out_features=1536, bias=True)\n",
      "Linear(in_features=1536, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=1152, bias=True)\n",
      "Linear(in_features=384, out_features=1536, bias=True)\n",
      "Linear(in_features=1536, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=1152, bias=True)\n",
      "Linear(in_features=384, out_features=1536, bias=True)\n",
      "Linear(in_features=1536, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=1152, bias=True)\n",
      "Linear(in_features=384, out_features=1536, bias=True)\n",
      "Linear(in_features=1536, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=1152, bias=True)\n",
      "Linear(in_features=384, out_features=1536, bias=True)\n",
      "Linear(in_features=1536, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=1152, bias=True)\n",
      "Linear(in_features=384, out_features=1536, bias=True)\n",
      "Linear(in_features=1536, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=1152, bias=True)\n",
      "Linear(in_features=384, out_features=1536, bias=True)\n",
      "Linear(in_features=1536, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=1152, bias=True)\n",
      "Linear(in_features=384, out_features=1536, bias=True)\n",
      "Linear(in_features=1536, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=1152, bias=True)\n",
      "Linear(in_features=384, out_features=1536, bias=True)\n",
      "Linear(in_features=1536, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=1152, bias=True)\n",
      "Linear(in_features=384, out_features=1536, bias=True)\n",
      "Linear(in_features=1536, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=384, bias=True)\n",
      "Linear(in_features=384, out_features=1152, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for ele in DINOv2.blocks:\n",
    "    if isinstance(ele, type(DINOv2.blocks[0])):\n",
    "        print(ele.mlp.fc1)\n",
    "        print(ele.mlp.fc2)\n",
    "        print(ele.attn.proj)\n",
    "        print(ele.attn.qkv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np\n",
    "\n",
    "def compute_centroids(weights, assignment):\n",
    "    # we are going to mean the neurons into the first index in the weights occuring in the assingment\n",
    "    first_indices = []\n",
    "    for i in range(int(assignment.max()) + 1):\n",
    "        indices = (assignment == i).nonzero()\n",
    "\n",
    "        first_index = indices[0]\n",
    "        \n",
    "        try:\n",
    "            first_indices.append(first_index.item())\n",
    "            weights[first_index, :] = weights[indices].mean(0)\n",
    "        except:\n",
    "            first_indices.append(first_index[0].item())\n",
    "            weights[first_index[0], :] = weights[indices[0]].mean(0)\n",
    "    first_indices.sort()\n",
    "\n",
    "    return weights[first_indices]\n",
    "\n",
    "\n",
    "def reduce_neurons(weight, bias=None, clusters=None, threshold=0.1):\n",
    "    if bias is None:\n",
    "        bias = torch.zeros((weight.shape[0]))\n",
    "\n",
    "    \n",
    "    weight = torch.concat((weight, bias.unsqueeze(-1)), 1)\n",
    "\n",
    "    normed = torch.nn.functional.normalize(weight)\n",
    "\n",
    "    D = (1.0 - (normed @ normed.T)).relu()\n",
    "    print(D.shape)\n",
    "    C = AgglomerativeClustering(clusters, affinity='precomputed', linkage='complete', compute_full_tree=True, distance_threshold=threshold)\n",
    "    assignment = C.fit_predict(D)\n",
    "\n",
    "    centroids = compute_centroids(weight, assignment)\n",
    "\n",
    "    bias, centroids = centroids[:, -1].squeeze(), centroids[:, :-1]\n",
    "\n",
    "    return centroids, bias, assignment\n",
    "\n",
    "\n",
    "def reduce_columns(weight, assignment):\n",
    "    # we are going to sum the columns into the first index in the weights occuring in the assignment\n",
    "    first_indices = []\n",
    "    for i in range(int(assignment.max())):\n",
    "        indices = (assignment == i).nonzero()\n",
    "\n",
    "        first_index = indices[0]\n",
    "\n",
    "        try:\n",
    "            first_indices.append(first_index.item())\n",
    "            weight[:, first_index] = weight[:, indices].sum(1)\n",
    "        except:\n",
    "            first_indices.append(first_index[0].item())\n",
    "            weight[:, first_index[0]] = weight[:, indices[0]].sum(1)\n",
    "\n",
    "    first_indices.sort()\n",
    "\n",
    "    return weight[:, first_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1536, 384])\n",
      "torch.Size([1536, 1536])\n",
      "1535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1536, 384])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DINOv2.cpu()\n",
    "print(DINOv2.blocks[0].mlp.fc1.weight.shape)\n",
    "weights, bias, assignment = reduce_neurons(DINOv2.blocks[0].mlp.fc1.weight.detach().clone(), threshold=-1)\n",
    "print(assignment.max())\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384, 1535])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = reduce_columns(DINOv2.blocks[0].mlp.fc2.weight.detach().clone(), assignment)\n",
    "cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def train(model, optimizer, loader):\n",
    "    model.train()\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for i, (X, y) in tqdm(enumerate(loader)):\n",
    "        out = model(X.to(0))\n",
    "        optimizer.zero_grad()\n",
    "        l = loss(out, y.to(0))\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    output = output.to(torch.device('cpu'))\n",
    "    target = target.to(torch.device('cpu'))\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.shape[0]\n",
    "\n",
    "    _, idx = output.sort(dim=1, descending=True)\n",
    "    pred = idx.narrow(1, 0, maxk).t()\n",
    "    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(dim=0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "def epoch_accuracy(loader_s, student):\n",
    "    student.eval()\n",
    "\n",
    "    out_epoch_s = [accuracy(student(L.to(0)), y)[0].detach().cpu().item() for L, y in loader_s]\n",
    "\n",
    "    student.train()\n",
    "\n",
    "    return sum(out_epoch_s) / len(out_epoch_s)\n",
    "\n",
    "def test(network, test_loader):\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    test_losses=[]\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data.to(0))\n",
    "            test_loss += torch.nn.CrossEntropyLoss()(output, target.to(0)).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1].cpu()\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_losses.append(test_loss)\n",
    "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "def latency(f, x, trials = 100):\n",
    "    total = 0.0\n",
    "    for trial in range(trials):\n",
    "        start = time.perf_counter()\n",
    "        f(x)\n",
    "        total += time.perf_counter() - start\n",
    "    return total / trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearProbe(torch.nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super().__init__()\n",
    "        self.m = module\n",
    "        self.linear = torch.nn.Linear(384, 102)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.m(x).detach()\n",
    "        return self.linear(x) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /vagrant/pytorch_models/hub\\facebookresearch_dinov2_main\n",
      "32it [00:09,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 1.7021, Accuracy: 285/1020 (28%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:09,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.3208, Accuracy: 738/1020 (72%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:09,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1298, Accuracy: 870/1020 (85%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:09,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1043, Accuracy: 898/1020 (88%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:10,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0948, Accuracy: 907/1020 (89%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:10,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0952, Accuracy: 906/1020 (89%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:10,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0949, Accuracy: 906/1020 (89%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:10,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0949, Accuracy: 906/1020 (89%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:10,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0949, Accuracy: 906/1020 (89%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:10,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0949, Accuracy: 906/1020 (89%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "train_ds = torchvision.datasets.Flowers102('./Flowers102', split='train', transform=DINOv2_transform, download=True)\n",
    "val_ds = torchvision.datasets.Flowers102('./Flowers102', split='val', transform=DINOv2_transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=32)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=48)\n",
    "\n",
    "DINOv2 = dino_model()\n",
    "\n",
    "model = LinearProbe(DINOv2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(10):\n",
    "    train(model.to(0), optimizer, train_loader)\n",
    "    gc.collect()\n",
    "    test(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size_train = 128\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.CIFAR100('./cifar100/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.CIFAR100('./cifar100/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                             ])),\n",
    "  batch_size=1024, shuffle=True)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(3072, 2048)\n",
    "        self.fc2 = torch.nn.Linear(2048, 1024)\n",
    "        self.fc3 = torch.nn.Linear(1024, 512)\n",
    "        self.fc4 = torch.nn.Linear(512, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x\n",
    "        x = torch.nn.Flatten()(x)\n",
    "        return torch.nn.functional.relu(self.fc4(torch.nn.functional.relu(self.fc3(torch.nn.functional.relu(self.fc2(torch.nn.functional.relu(self.fc1(x))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LowRankLinear(torch.nn.Module):\n",
    "    # takes in a linear layer and decomposes it into two low-rank linear layers\n",
    "    def __init__(self, fc, rank):\n",
    "        super(LowRankLinear, self).__init__()\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(fc.weight.shape[1], rank, bias = False)\n",
    "        self.fc2 = torch.nn.Linear(rank, fc.weight.shape[0])\n",
    "        \n",
    "        weight1 = fc.weight\n",
    "\n",
    "        self.fc2.bias = fc.bias\n",
    "\n",
    "        W1 = weight1.cpu().detach().clone().numpy()\n",
    "\n",
    "        U1, E1, V1 = np.linalg.svd(W1, False)\n",
    "\n",
    "        rd1 = np.zeros((len(E1), len(E1)))\n",
    "\n",
    "        for i, v in enumerate(E1):\n",
    "            rd1[i, i] = v\n",
    "\n",
    "\n",
    "        if fc.weight.shape[1] > fc.weight.shape[0]:\n",
    "            # if the input dom of the fc is bigger than the output dim\n",
    "            self.fc1.weight = torch.nn.parameter.Parameter(torch.tensor(rd1[:rank, :rank] @ V1[:rank, :]).to(fc.weight.device).type(fc.weight.dtype))\n",
    "            self.fc2.weight = torch.nn.parameter.Parameter(torch.tensor(U1[:, :rank]).to(fc.weight.device).type(fc.weight.dtype))\n",
    "        else:\n",
    "            self.fc1.weight = torch.nn.parameter.Parameter(torch.tensor(V1[:rank, :]).to(fc.weight.device).type(fc.weight.dtype))\n",
    "            self.fc2.weight = torch.nn.parameter.Parameter(torch.tensor(U1[:, :rank] @ rd1[:rank, :rank]).to(fc.weight.device).type(fc.weight.dtype))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.fc1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:12, 32.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0045, Accuracy: 511/10000 (5%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:12, 32.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0044, Accuracy: 824/10000 (8%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:12, 31.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0044, Accuracy: 1022/10000 (10%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:12, 32.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0043, Accuracy: 1180/10000 (12%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:12, 32.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0043, Accuracy: 1278/10000 (13%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network = Net().to(0)\n",
    "optimizer = torch.optim.SGD(network.parameters(), lr=1e-2,\n",
    "                      momentum=0.5)\n",
    "\n",
    "for epoch in range(5):\n",
    "    train(network.to(0), optimizer, train_loader)\n",
    "    gc.collect()\n",
    "    test(network, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=3072, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=100, bias=True)\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11656/80944960.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompressed_net\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompressed_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mcompressed_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLowRankLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11656/3894560031.py\u001b[0m in \u001b[0;36mlatency\u001b[1;34m(f, i, trials)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtotal\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jaycr\\anaconda3\\envs\\tfnew\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1517\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1518\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1520\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jaycr\\anaconda3\\envs\\tfnew\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1525\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11656/3388866939.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\jaycr\\anaconda3\\envs\\tfnew\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1517\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1518\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1520\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jaycr\\anaconda3\\envs\\tfnew\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1525\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jaycr\\anaconda3\\envs\\tfnew\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from copy import deepcopy as copy\n",
    "\n",
    "compressed_net = copy(network)\n",
    "\n",
    "\n",
    "print(latency(compressed_net.eval(), torch.ones(1, 3, 32, 32).to(0)))\n",
    "\n",
    "compressed_net.fc1 = LowRankLinear(network.fc1, 64)\n",
    "compressed_net.fc2 = LowRankLinear(network.fc2, 64)\n",
    "\n",
    "\n",
    "print(latency(compressed_net.eval(), torch.ones(1, 3, 32, 32)))\n",
    "\n",
    "compressed_net.fc1 = LowRankLinear(network.fc1, 32)\n",
    "compressed_net.fc2 = LowRankLinear(network.fc2, 32)\n",
    "\n",
    "\n",
    "print(latency(compressed_net.eval(), torch.ones(1, 3, 32, 32)))\n",
    "\n",
    "compressed_net.fc1 = LowRankLinear(network.fc1, 16)\n",
    "compressed_net.fc2 = LowRankLinear(network.fc2, 16)\n",
    "\n",
    "\n",
    "print(latency(compressed_net.eval(), torch.ones(1, 3, 32, 32)))\n",
    "\n",
    "compressed_net.fc1 = LowRankLinear(network.fc1, 8)\n",
    "compressed_net.fc2 = LowRankLinear(network.fc2, 8)\n",
    "\n",
    "print(latency(compressed_net.eval(), torch.ones(1, 3, 32, 32)))\n",
    "\n",
    "compressed_net.fc1 = LowRankLinear(network.fc1, 4)\n",
    "compressed_net.fc2 = LowRankLinear(network.fc2, 4)\n",
    "\n",
    "\n",
    "print(latency(compressed_net.eval(), torch.ones(1, 3, 32, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0020964660000026922\n",
      "0.00046075300000666177\n",
      "0.0003538460000891064\n",
      "0.00036670999998023035\n",
      "0.0002999140000065381\n",
      "0.00028197599998748047\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from copy import deepcopy as copy\n",
    "\n",
    "network.cpu()\n",
    "compressed_net = copy(network)\n",
    "\n",
    "def lowranklatency(module, rank):\n",
    "    module = copy(module)\n",
    "    for mod in module.children():\n",
    "        if isinstance(mod, torch.nn.Linear):\n",
    "            mod = LowRankLinear(mod, rank)\n",
    "\n",
    "    print(latency(module.eval(), torch.ones(64, 3, 32, 32)))\n",
    "\n",
    "print(latency(compressed_net.eval(), torch.ones(64, 3, 32, 32)))\n",
    "\n",
    "compressed_net.fc1 = LowRankLinear(network.fc1, 64)\n",
    "compressed_net.fc2 = LowRankLinear(network.fc2, 64)\n",
    "\n",
    "print(latency(compressed_net.eval(), torch.ones(64, 3, 32, 32)))\n",
    "\n",
    "compressed_net.fc1 = LowRankLinear(network.fc1, 32)\n",
    "compressed_net.fc2 = LowRankLinear(network.fc2, 32)\n",
    "\n",
    "\n",
    "print(latency(compressed_net.eval(), torch.ones(64, 3, 32, 32)))\n",
    "\n",
    "compressed_net.fc1 = LowRankLinear(network.fc1, 16)\n",
    "compressed_net.fc2 = LowRankLinear(network.fc2, 16)\n",
    "\n",
    "\n",
    "print(latency(compressed_net.eval(), torch.ones(64, 3, 32, 32)))\n",
    "\n",
    "compressed_net.fc1 = LowRankLinear(network.fc1, 8)\n",
    "compressed_net.fc2 = LowRankLinear(network.fc2, 8)\n",
    "\n",
    "\n",
    "print(latency(compressed_net.eval(), torch.ones(64, 3, 32, 32)))\n",
    "\n",
    "compressed_net.fc1 = LowRankLinear(network.fc1, 4)\n",
    "compressed_net.fc2 = LowRankLinear(network.fc2, 4)\n",
    "\n",
    "print(latency(compressed_net.eval(), torch.ones(64, 3, 32, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.cpu()\n",
    "compressed_net = copy(network)\n",
    "\n",
    "def lowranklatency(module, rank):\n",
    "    module = copy(module)\n",
    "    for name, mod in module.named_modules():\n",
    "        if isinstance(mod, torch.nn.Linear):\n",
    "            module.add_module(name, LowRankLinear(mod, rank))\n",
    "    print(module)\n",
    "    print(latency(module.eval(), torch.ones(64, 3, 32, 32)))\n",
    "\n",
    "for rank in range(2, 128, 2):\n",
    "    lowranklatency(compressed_net, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfnew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
